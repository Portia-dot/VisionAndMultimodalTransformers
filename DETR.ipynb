{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-18T02:41:25.153268Z",
     "start_time": "2025-11-18T02:41:25.150889Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.ops import generalized_box_iou\n",
    "import torch.nn.functional as F\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from typing import Tuple\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T02:41:25.181633Z",
     "start_time": "2025-11-18T02:41:25.165772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cxcywh_to_xyxy(boxes):\n",
    "    cx, cy, w, h = boxes.unbind(-1)\n",
    "    x1 = cx - 0.5 * w\n",
    "    y1 = cy - 0.5 * h\n",
    "    x2 = cx + 0.5 * w\n",
    "    y2 = cy + 0.5 * h\n",
    "    return torch.stack((x1, y1, x2, y2), dim=-1)"
   ],
   "id": "93140b5a926619f0",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T02:41:25.189881Z",
     "start_time": "2025-11-18T02:41:25.184560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class HungarianMatcher(nn.Module):\n",
    "    def __init__(self, cost_class: float = 1, cost_bbox: float = 1, cost_giou: float = 2):\n",
    "        super(HungarianMatcher, self).__init__()\n",
    "\n",
    "        self.cost_class = cost_class\n",
    "        self.cost_bbox = cost_bbox\n",
    "        self.cost_giou = cost_giou\n",
    "\n",
    "    def _get_index_map(self, targets):\n",
    "        batch_idx = torch.cat([torch.full((len(t['labels']),), i, dtype=torch.int64)\n",
    "                               for i, t in enumerate(targets)])\n",
    "        gt_idx = torch.cat([torch.arange(len(t['labels']), dtype=torch.int64)\n",
    "                            for t in targets])\n",
    "        return batch_idx, gt_idx\n",
    "\n",
    "    #Manhattan distance between predicted and GTBoxes\n",
    "\n",
    "    def _bbox_distance(self, pred_boxes, targets):\n",
    "        boxes = torch.cat([t['boxes'] for t in targets])\n",
    "        pred_boxes = pred_boxes.view(-1, 4)\n",
    "        cost = torch.cdist(pred_boxes, boxes, p=1)\n",
    "        return cost\n",
    "\n",
    "    def _giou_loss(self, pred_boxes, targets):\n",
    "        all_cost = []\n",
    "\n",
    "        for i, t in enumerate(targets):\n",
    "            preds = pred_boxes[i]\n",
    "            gts = t['boxes']\n",
    "\n",
    "            if len(gts) == 0:\n",
    "                all_cost.append(torch.zeros(preds.size(0), device=preds.device))\n",
    "                continue\n",
    "            pred_xyxy = cxcywh_to_xyxy(preds)\n",
    "            targetxyxy = cxcywh_to_xyxy(gts)\n",
    "\n",
    "            giou = generalized_box_iou(pred_xyxy, targetxyxy)\n",
    "            best_giou_per_pred = giou.max(dim=-1)[0]\n",
    "            all_cost.append(-best_giou_per_pred)\n",
    "        return all_cost\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, outputs, targets):\n",
    "        bs, num_queries = outputs['pred_logits'].shape[:2]\n",
    "        indices = []\n",
    "\n",
    "        for i in range(bs):\n",
    "            # --- extract predictions for this image ---\n",
    "            out_prob = outputs['pred_logits'][i].softmax(-1)  # [N, C]\n",
    "            out_bbox = outputs['pred_boxes'][i]  # [N, 4]\n",
    "\n",
    "            tgt_ids = targets[i]['labels']  # [K]\n",
    "            tgt_bbox = targets[i]['boxes']  # [K, 4]\n",
    "\n",
    "            # --- compute costs ---\n",
    "            cost_class = -out_prob[:, tgt_ids]  # [N, K]\n",
    "            cost_bbox = torch.cdist(out_bbox, tgt_bbox, p=1)  # [N, K]\n",
    "            cost_giou = -generalized_box_iou(\n",
    "            cxcywh_to_xyxy(out_bbox), cxcywh_to_xyxy(tgt_bbox)\n",
    "            )  # [N, K]\n",
    "\n",
    "            # --- total cost ---\n",
    "            C = (self.cost_class * cost_class +\n",
    "                 self.cost_bbox * cost_bbox +\n",
    "                 self.cost_giou * cost_giou)\n",
    "\n",
    "            i_idx, j_idx = linear_sum_assignment(C.cpu())\n",
    "            indices.append((\n",
    "                torch.as_tensor(i_idx, dtype=torch.int64),\n",
    "                torch.as_tensor(j_idx, dtype=torch.int64)\n",
    "            ))\n",
    "\n",
    "        return indices\n",
    "\n"
   ],
   "id": "a43006b674fcc9a4",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T02:41:25.198126Z",
     "start_time": "2025-11-18T02:41:25.192756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Understand the Set Criterion\n",
    "class SetCriterion(nn.Module):\n",
    "    def __init__(self, matcher, weight_dict, eos_coef=0.1, losses=None):\n",
    "        super(SetCriterion, self).__init__()\n",
    "        if losses is None:\n",
    "            losses = ['labels', 'boxes']\n",
    "        self.matcher = matcher\n",
    "        self.weight_dict = weight_dict\n",
    "        self.eos_coef = eos_coef\n",
    "        self.losses = losses\n",
    "\n",
    "    def _get_src_batch_indices(self, indices):\n",
    "        batch_idx = torch.cat(\n",
    "            [torch.full((len(src),), i, dtype=torch.int64)\n",
    "             for i, (src, _) in enumerate(indices)]\n",
    "        )\n",
    "        src_idx = torch.cat(\n",
    "            [src for (src, _) in indices]\n",
    "        )\n",
    "        return batch_idx, src_idx\n",
    "\n",
    "    def loss_labels(self, outputs, targets, indices, num_boxes):\n",
    "        \"\"\"Compute classification loss for matched predictions only\"\"\"\n",
    "        batch_idx, src_idx = self._get_src_batch_indices(indices)\n",
    "        pred_logits = outputs['pred_logits'][batch_idx, src_idx]\n",
    "        #Ground truth label for the same box\n",
    "        target_classes = torch.cat([t['labels'][J] for t, (_, J) in zip(targets, indices)])\n",
    "        #Compute loss function\n",
    "        loss_ce = F.cross_entropy(pred_logits, target_classes, reduction='none')\n",
    "        weights = torch.ones_like(target_classes, dtype=torch.float)\n",
    "        loss = (loss_ce * weights).sum() / num_boxes\n",
    "        return {'loss_ce': loss}\n",
    "\n",
    "    def loss_boxes(self, outputs, targets, indices, num_boxes):\n",
    "        \"\"\"Compute DETR box regress loss\"\"\"\n",
    "        batch_idx, src_idx =self._get_src_batch_indices(indices)\n",
    "        src_boxes = outputs['pred_boxes'][batch_idx, src_idx]\n",
    "\n",
    "        #Get each box ground truth\n",
    "        target_boxes = torch.cat(\n",
    "            [t['boxes'][J] for t, (_, J) in zip(targets, indices)],\n",
    "        )\n",
    "\n",
    "         # L1 loss   numeric distance between boxes\n",
    "        loss_bbox = F.l1_loss(src_boxes, target_boxes, reduction='none')\n",
    "        loss_bbox = loss_bbox.sum()/ num_boxes\n",
    "\n",
    "        #GIOU Loss (Overlapping Boxes)\n",
    "        src_xyxy = cxcywh_to_xyxy(src_boxes)\n",
    "        target_xyxy = cxcywh_to_xyxy(target_boxes)\n",
    "\n",
    "        giou = generalized_box_iou(src_xyxy, target_xyxy)\n",
    "        giou = torch.nan_to_num(giou, nan= 0.0, posinf=0.0, neginf=-1.0)\n",
    "        loss_giou = (1 - torch.diag(giou)).sum() / num_boxes\n",
    "\n",
    "        return {'loss_box':loss_bbox, 'loss_giou': loss_giou}\n",
    "\n",
    "\n",
    "    def forward(self, outputs, targets ):\n",
    "        \"\"\"Compute the total DETR LOSS\"\"\"\n",
    "        indices = self.matcher(outputs, targets)\n",
    "        num_boxes = sum(len(t['labels']) for t in targets)\n",
    "        num_boxes = torch.as_tensor([num_boxes], dtype=torch.float, device = next(iter(outputs.values())).device)\n",
    "        if torch.distributed.is_available() and torch.distributed.is_initialized():\n",
    "            torch.distributed.all_reduce(num_boxes)\n",
    "            num_boxes = num_boxes / torch.distributed.get_world_size()\n",
    "        num_boxes = max(num_boxes.item(), 1.0)\n",
    "\n",
    "        losses ={}\n",
    "\n",
    "        for loss in self.losses:\n",
    "            if loss == 'labels':\n",
    "                losses.update(self.loss_labels(outputs, targets, indices, num_boxes))\n",
    "            elif loss == 'boxes':\n",
    "                losses.update(self.loss_boxes(outputs, targets, indices, num_boxes))\n",
    "        total_loss = sum(self.weight_dict[k] * v for k, v in losses.items() if k in self.weight_dict)\n",
    "        return total_loss, losses"
   ],
   "id": "a24d0d3738b0df2",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T02:41:25.207647Z",
     "start_time": "2025-11-18T02:41:25.202001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "outputs = {\n",
    "    \"pred_logits\": torch.randn(2, 5, 91),  # 2 images, 5 queries each\n",
    "    \"pred_boxes\": torch.rand(2, 5, 4)\n",
    "}\n",
    "targets = [\n",
    "    {\"labels\": torch.tensor([3, 5, 7]), \"boxes\": torch.rand(3, 4)},\n",
    "    {\"labels\": torch.tensor([4, 8]), \"boxes\": torch.rand(2, 4)}\n",
    "]\n",
    "matcher = HungarianMatcher()\n",
    "indices = matcher(outputs, targets)\n",
    "print(indices)\n"
   ],
   "id": "29d51ce5e490bdf6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor([0, 1, 2]), tensor([1, 0, 2])), (tensor([0, 4]), tensor([1, 0]))]\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T02:41:25.229902Z",
     "start_time": "2025-11-18T02:41:25.221772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "weight_dict = {'loss_ce': 1.0, 'loss_bbox': 5.0, 'loss_giou': 2.0}\n",
    "outputs = {\n",
    "    \"pred_logits\": torch.randn(2, 5, 91),\n",
    "    \"pred_boxes\": torch.rand(2, 5, 4)\n",
    "}\n",
    "targets = [\n",
    "    {\"labels\": torch.tensor([3, 5, 7]), \"boxes\": torch.rand(3, 4)},\n",
    "    {\"labels\": torch.tensor([4, 8]), \"boxes\": torch.rand(2, 4)}\n",
    "]\n",
    "\n",
    "matcher = HungarianMatcher()\n",
    "criterion = SetCriterion(matcher, weight_dict, eos_coef=0.1, losses=['labels', 'boxes'])\n",
    "\n",
    "total_loss, loss_dict = criterion(outputs, targets)\n",
    "print(\"Matched indices:\", matcher(outputs, targets))\n",
    "print(\"Total loss:\", total_loss)\n",
    "print(\"Loss breakdown:\", loss_dict)\n"
   ],
   "id": "ca96ec9756db8e97",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched indices: [(tensor([0, 1, 3]), tensor([2, 0, 1])), (tensor([3, 4]), tensor([1, 0]))]\n",
      "Total loss: tensor(7.6155)\n",
      "Loss breakdown: {'loss_ce': tensor(5.3163), 'loss_box': tensor(1.1238), 'loss_giou': tensor(1.1496)}\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T02:41:25.243233Z",
     "start_time": "2025-11-18T02:41:25.238857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchvision.models as models\n",
    "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
    "class Backbone(nn.Module):\n",
    "    def __init__(self, backbone_name = 'resnet50', dilation = False, return_layers = None):\n",
    "        super().__init__()\n",
    "        if return_layers is None:\n",
    "            return_layers = {'layer4': '0'}\n",
    "        backbone = getattr(models, backbone_name)(pretrained=True, replace_stride_with_dilation = [False, False, dilation])\n",
    "        self.body = backbone\n",
    "\n",
    "        if dilation:\n",
    "            self.body.layer4[0].downsample[0].stride = (1, 1)\n",
    "            self.body.layer4[0].conv2.stride = (1, 1)\n",
    "            self.body.layer4[2].conv1.stride = (1, 1)\n",
    "            self.body.layer4[2].conv2.stride = (1, 1)\n",
    "            self.body.layer4[2].downsample[0].stride = (1, 1)\n",
    "\n",
    "        self.out_channels = 2048 if backbone_name == 'resnet101' else 256 * 8\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.body.conv1(inputs)\n",
    "        x =self.body.bn1(x)\n",
    "        x = self.body.relu(x)\n",
    "        x = self.body.maxpool(x)\n",
    "        x = self.body.layer1(x)\n",
    "        x = self.body.layer2(x)\n",
    "        x = self.body.layer3(x)\n",
    "        x = self.body.layer4(x)\n",
    "        return x\n"
   ],
   "id": "5ef02543b6fe93f3",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T02:42:33.840003Z",
     "start_time": "2025-11-18T02:42:33.836340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() *\n",
    "                             (-torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))  # (1, max_len, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Detect layout: batch-first or sequence-first\n",
    "        if x.dim() == 3 and x.shape[0] < x.shape[1]:\n",
    "            # Likely (seq_len, batch, d_model)\n",
    "            seq_len = x.size(0)\n",
    "            return x + self.pe[:, :seq_len, :].transpose(0, 1)\n",
    "        else:\n",
    "            # Likely (batch, seq_len, d_model)\n",
    "            seq_len = x.size(1)\n",
    "            return x + self.pe[:, :seq_len, :]\n"
   ],
   "id": "bb7bfd1822b12172",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T02:54:46.154634Z",
     "start_time": "2025-11-18T02:54:46.143109Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import math\n",
    "\n",
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % nhead == 0\n",
    "        self.d_model = d_model\n",
    "        self.nhead = nhead\n",
    "        self.head_dim = d_model // nhead\n",
    "\n",
    "        self.q_proj = nn.Linear(d_model, d_model)\n",
    "        self.k_proj = nn.Linear(d_model, d_model)\n",
    "        self.v_proj = nn.Linear(d_model, d_model)\n",
    "        self.out_proj = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.scale = math.sqrt(self.head_dim)\n",
    "\n",
    "    def forward(self, query: Tensor, key: Tensor, value: Tensor, attn_mask=None, key_padding_mask=None) -> Tensor:\n",
    "        # --- Detect layout (batch-first vs seq-first) ---\n",
    "        if query.dim() == 3 and query.shape[0] < query.shape[1]:\n",
    "            # seq-first layout (L, B, D)\n",
    "            query = query.transpose(0, 1)  # -> (B, L, D)\n",
    "            key = key.transpose(0, 1)\n",
    "            value = value.transpose(0, 1)\n",
    "            seq_first = True\n",
    "        else:\n",
    "            seq_first = False\n",
    "\n",
    "        B, tgt_len, d = query.shape\n",
    "        src_len = key.shape[1]\n",
    "\n",
    "        # --- Project Q, K, V ---\n",
    "        Q = self.q_proj(query).view(B, tgt_len, self.nhead, self.head_dim).transpose(1, 2)\n",
    "        K = self.k_proj(key).view(B, src_len, self.nhead, self.head_dim).transpose(1, 2)\n",
    "        V = self.v_proj(value).view(B, src_len, self.nhead, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        # --- Attention weights ---\n",
    "        attn = (Q @ K.transpose(-2, -1)) / self.scale  # (B, nhead, tgt, src)\n",
    "        if attn_mask is not None:\n",
    "            attn += attn_mask\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        # --- Weighted sum ---\n",
    "        out = (attn @ V).transpose(1, 2).contiguous().view(B, tgt_len, d)\n",
    "        out = self.out_proj(out)\n",
    "\n",
    "        # --- Convert back if needed ---\n",
    "        if seq_first:\n",
    "            out = out.transpose(0, 1)  # -> (L, B, D)\n",
    "        return out\n"
   ],
   "id": "2315f235b81e160c",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T02:57:01.193928Z",
     "start_time": "2025-11-18T02:57:01.180489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "#Opt for pytorch builtin transformer\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.nn import TransformerDecoder, TransformerDecoderLayer\n",
    "\n",
    "class DETR(nn.Module):\n",
    "    def __init__(self, num_classes=20, num_queries=100, d_model=256, nhead=8,\n",
    "                 num_encoder_layers=6, num_decoder_layers=6,\n",
    "                 dim_feedforward=2048, dropout=0.1, backbone='resnet50', dilation=False):\n",
    "        super().__init__()\n",
    "        self.num_queries = num_queries\n",
    "        self.d_model = d_model\n",
    "        self.num_classes = num_classes + 1  # + âˆ…\n",
    "\n",
    "        # Backbone + projection\n",
    "        self.backbone = Backbone(backbone, dilation)\n",
    "        self.conv = nn.Conv2d(self.backbone.out_channels, d_model, 1)\n",
    "\n",
    "        # Positional encodings\n",
    "        self.encoder_pe = PositionalEncoding(d_model)\n",
    "        self.decoder_pe = PositionalEncoding(d_model, num_queries)\n",
    "\n",
    "        # Transformer (batch_first=True)\n",
    "        encoder_layer = TransformerEncoderLayer(\n",
    "            d_model, nhead, dim_feedforward, dropout, batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layer, num_encoder_layers)\n",
    "\n",
    "        decoder_layer = TransformerDecoderLayer(\n",
    "            d_model, nhead, dim_feedforward, dropout, batch_first=True\n",
    "        )\n",
    "        self.transformer_decoder = TransformerDecoder(decoder_layer, num_decoder_layers)\n",
    "\n",
    "        # Object queries\n",
    "        self.query_embed = nn.Embedding(num_queries, d_model)\n",
    "\n",
    "        # Prediction heads\n",
    "        self.class_embed = nn.Linear(d_model, num_classes)\n",
    "        self.bbox_embed = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model, 4),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # Criterion\n",
    "        matcher = HungarianMatcher(cost_class=1, cost_bbox=5, cost_giou=2)\n",
    "        weight_dict = {'loss_ce': 1, 'loss_bbox': 5, 'loss_giou': 2}\n",
    "        self.criterion = SetCriterion(matcher, weight_dict, eos_coef=0.1, losses=['labels', 'boxes'])\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "        # Backbone feature extraction\n",
    "        features = self.backbone(x)\n",
    "        features = self.conv(features)\n",
    "        B, C, H, W = features.shape\n",
    "        src = features.flatten(2).transpose(1, 2)\n",
    "\n",
    "        # Add positional encoding\n",
    "        src = self.encoder_pe(src)\n",
    "\n",
    "        # Transformer encoder\n",
    "        memory = self.transformer_encoder(src)\n",
    "\n",
    "        # Prepare queries\n",
    "        query_embed = self.query_embed.weight.unsqueeze(0).repeat(B, 1, 1)\n",
    "        tgt = torch.zeros_like(query_embed)\n",
    "        query_embed = self.decoder_pe(query_embed)\n",
    "\n",
    "        # Transformer decoder\n",
    "        hs = self.transformer_decoder(tgt, memory)  \n",
    "\n",
    "        # Predictions\n",
    "        outputs_class = self.class_embed(hs)\n",
    "        outputs_coord = self.bbox_embed(hs)\n",
    "        out = {'pred_logits': outputs_class, 'pred_boxes': outputs_coord}\n",
    "\n",
    "        if self.training and targets is not None:\n",
    "            loss_dict = self.criterion(out, targets)\n",
    "            return loss_dict\n",
    "\n",
    "        return out\n"
   ],
   "id": "e56670aeba735951",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T02:57:17.046971Z",
     "start_time": "2025-11-18T02:57:12.229393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = DETR(num_classes=20)\n",
    "x = torch.randn(2, 3, 800, 1333)\n",
    "out = model(x)\n",
    "print(out['pred_logits'].shape, out['pred_boxes'].shape)\n"
   ],
   "id": "451654c424ac1243",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 100, 20]) torch.Size([2, 100, 4])\n"
     ]
    }
   ],
   "execution_count": 48
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
